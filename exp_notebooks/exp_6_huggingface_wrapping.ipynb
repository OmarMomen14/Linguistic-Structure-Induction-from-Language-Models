{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import structformer\n",
    "import data_ptb_subword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = torch.load('../trained_models/babylm_1111_sf_2.pt')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained('omarmomen/babylm_bpe_tokenizer_16k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = structformer.StructFormerConfig(\n",
    "    hidden_size=pretrained_model.hidden_size,\n",
    "    nlayers=pretrained_model.nlayers,\n",
    "    ntokens=pretrained_model.ntokens,\n",
    "    nhead=pretrained_model.nhead,\n",
    "    pos_emb=True if pretrained_model.pos_emb else False,\n",
    "    pad=pretrained_model.pad,\n",
    "    n_parser_layers=pretrained_model.n_parse_layers,\n",
    "    relations=pretrained_model.relations,\n",
    "    weight_act=pretrained_model.weight_act\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = structformer.StructFormerModel(config).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1015494it [00:45, 22445.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "96105it [00:04, 20769.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "95681it [00:04, 19893.30it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = data_ptb_subword.SubWord_Corpus_Custom(\"omarmomen/babylm_bpe_tokenizer_16k\", \"../data/babylm_10M/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output1 = model(torch.LongTensor([dataset.test[0]]).to('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 16000])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output1['logits'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'All round  Street and that way.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(dataset.test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CheckFireCheck localitiesCheckianWhoever device'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(output1['logits'].argmax(-1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output1.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_state_dict = pretrained_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_state_dict = {f\"model.{k}\": v for k, v in loaded_state_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(loaded_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "output2 = model(torch.LongTensor([dataset.test[0]]).to('cuda'), labels=torch.LongTensor([dataset.test[0]]).to('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'All round  Street and that way.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(dataset.test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'All round  Street, that way.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(output2['logits'].argmax(-1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6461, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output2.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "structformer.StructFormerConfig.register_for_auto_class()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "structformer.StructFormerModel.register_for_auto_class(\"AutoModelForMaskedLM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "structformer.StructFormerModelForSequenceClassification.register_for_auto_class(\"AutoModelForMaskedLM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.save_pretrained('../saved_hf_models/sf_babylm_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../saved_hf_models/sf_babylm_1/tokenizer_config.json',\n",
       " '../saved_hf_models/sf_babylm_1/special_tokens_map.json',\n",
       " '../saved_hf_models/sf_babylm_1/vocab.json',\n",
       " '../saved_hf_models/sf_babylm_1/merges.txt',\n",
       " '../saved_hf_models/sf_babylm_1/added_tokens.json',\n",
       " '../saved_hf_models/sf_babylm_1/tokenizer.json')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained('../saved_hf_models/sf_babylm_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('../saved_hf_models/sf_babylm_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "structformer.StructFormerConfig.register_for_auto_class()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "structformer.StructFormerModel.register_for_auto_class(\"AutoModelForMaskedLM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "structformer.StructFormerModelForSequenceClassification.register_for_auto_class(\"AutoModelForMaskedLM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/miniconda3/envs/structformer/lib/python3.6/site-packages/huggingface_hub/hf_api.py:1004: FutureWarning: `create_repo` now takes `token` as an optional positional argument. Be sure to adapt your code!\n",
      "  FutureWarning,\n",
      "Cloning https://huggingface.co/omarmomen/sf_babylm_1 into local empty directory.\n",
      "To https://huggingface.co/omarmomen/sf_babylm_1\n",
      "   6425019..257e44a  main -> main\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/omarmomen/sf_babylm_1/commit/257e44ae8dccb0f3184824752e1166e343586394'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.push_to_hub(\"sf_babylm_1\", use_temp_dir=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/miniconda3/envs/structformer/lib/python3.6/site-packages/huggingface_hub/hf_api.py:1004: FutureWarning: `create_repo` now takes `token` as an optional positional argument. Be sure to adapt your code!\n",
      "  FutureWarning,\n",
      "Cloning https://huggingface.co/omarmomen/sf_babylm_1 into local empty directory.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d12322b419f4db9a2b6ab411fccedc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 1.00/159M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/omarmomen/sf_babylm_1\n",
      "   257e44a..4ef095f  main -> main\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/omarmomen/sf_babylm_1/commit/4ef095f84ae19d50ad8da3ea0aa207fc6bbccfe5'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(\"sf_babylm_1\", use_temp_dir=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07113512cce848e4882a8f97f1df9c29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/18.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57bdc9a52cea40aaab5ce968b2abca92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/159M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained('omarmomen/sf_babylm_1')\n",
    "model = transformers.AutoModelForMaskedLM.from_pretrained('omarmomen/sf_babylm_1', trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructFormerModel(\n",
       "  (model): StructFormer(\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (emb): Embedding(16000, 512)\n",
       "    (pos_emb): Embedding(500, 512)\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (feedforward): Sequential(\n",
       "          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "          (4): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (feedforward): Sequential(\n",
       "          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "          (4): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (feedforward): Sequential(\n",
       "          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "          (4): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (3): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (feedforward): Sequential(\n",
       "          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "          (4): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (4): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (feedforward): Sequential(\n",
       "          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "          (4): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (5): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (feedforward): Sequential(\n",
       "          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "          (4): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (6): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (feedforward): Sequential(\n",
       "          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "          (4): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (7): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (feedforward): Sequential(\n",
       "          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "          (4): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (output_layer): Linear(in_features=512, out_features=16000, bias=True)\n",
       "    (parser_layers): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Conv1d(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(9,), stride=(1,), padding=(4,))\n",
       "        )\n",
       "        (1): LayerNorm((512,), eps=1e-05, elementwise_affine=False)\n",
       "        (2): Tanh()\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv1d(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(9,), stride=(1,), padding=(4,))\n",
       "        )\n",
       "        (1): LayerNorm((512,), eps=1e-05, elementwise_affine=False)\n",
       "        (2): Tanh()\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Conv1d(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(9,), stride=(1,), padding=(4,))\n",
       "        )\n",
       "        (1): LayerNorm((512,), eps=1e-05, elementwise_affine=False)\n",
       "        (2): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (distance_ff): Sequential(\n",
       "      (0): Conv1d(\n",
       "        (conv): Conv1d(512, 512, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "      )\n",
       "      (1): LayerNorm((512,), eps=1e-05, elementwise_affine=False)\n",
       "      (2): Tanh()\n",
       "      (3): Linear(in_features=512, out_features=1, bias=True)\n",
       "    )\n",
       "    (height_ff): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): LayerNorm((512,), eps=1e-05, elementwise_affine=False)\n",
       "      (2): Tanh()\n",
       "      (3): Linear(in_features=512, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(torch.LongTensor([dataset.test[0]]).to('cuda'), labels=torch.LongTensor([dataset.test[0]]).to('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'All round  Street and that way.'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(dataset.test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'All round  Street, that way.'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(output['logits'].argmax(-1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3652, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b82ae6e2d11b4baf95cf6e5117bd217e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/774 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "370e07da29064c32ab041976c95b30a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/19.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Some weights of StructFormerModelForSequenceClassification were not initialized from the model checkpoint at omarmomen/sf_babylm_1 and are newly initialized: ['model.classifier.out_proj.bias', 'model.classifier.dense.weight', 'model.classifier.out_proj.weight', 'model.classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained('omarmomen/sf_babylm_1')\n",
    "model     = transformers.AutoModelForSequenceClassification.from_pretrained('omarmomen/sf_babylm_1', trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructFormerModelForSequenceClassification(\n",
       "  (model): StructFormer(\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (emb): Embedding(16000, 512)\n",
       "    (pos_emb): Embedding(500, 512)\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (feedforward): Sequential(\n",
       "          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "          (4): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (feedforward): Sequential(\n",
       "          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "          (4): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (feedforward): Sequential(\n",
       "          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "          (4): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (3): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (feedforward): Sequential(\n",
       "          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "          (4): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (4): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (feedforward): Sequential(\n",
       "          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "          (4): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (5): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (feedforward): Sequential(\n",
       "          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "          (4): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (6): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (feedforward): Sequential(\n",
       "          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "          (4): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (7): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (feedforward): Sequential(\n",
       "          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "          (4): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (output_layer): Linear(in_features=512, out_features=16000, bias=True)\n",
       "    (parser_layers): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Conv1d(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(9,), stride=(1,), padding=(4,))\n",
       "        )\n",
       "        (1): LayerNorm((512,), eps=1e-05, elementwise_affine=False)\n",
       "        (2): Tanh()\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv1d(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(9,), stride=(1,), padding=(4,))\n",
       "        )\n",
       "        (1): LayerNorm((512,), eps=1e-05, elementwise_affine=False)\n",
       "        (2): Tanh()\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Conv1d(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(9,), stride=(1,), padding=(4,))\n",
       "        )\n",
       "        (1): LayerNorm((512,), eps=1e-05, elementwise_affine=False)\n",
       "        (2): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (distance_ff): Sequential(\n",
       "      (0): Conv1d(\n",
       "        (conv): Conv1d(512, 512, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "      )\n",
       "      (1): LayerNorm((512,), eps=1e-05, elementwise_affine=False)\n",
       "      (2): Tanh()\n",
       "      (3): Linear(in_features=512, out_features=1, bias=True)\n",
       "    )\n",
       "    (height_ff): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): LayerNorm((512,), eps=1e-05, elementwise_affine=False)\n",
       "      (2): Tanh()\n",
       "      (3): Linear(in_features=512, out_features=1, bias=True)\n",
       "    )\n",
       "    (classifier): ClassificationHead(\n",
       "      (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (out_proj): Linear(in_features=512, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(torch.LongTensor([dataset.test[0]]).to('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0475, -0.0517]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'All round  Street and that way.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer.decode(dataset.test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'All round  Street, that way.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer.decode(output['logits'].argmax(-1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3652, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import structformer_in_parser\n",
    "import data_ptb_subword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = torch.load('../trained_models/babylm_1111_in_parser_sf.pt')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained('omarmomen/babylm_bpe_tokenizer_16k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = structformer_in_parser.StructFormer_In_ParserConfig(\n",
    "    hidden_size=pretrained_model.transformer_front.hidden_size,\n",
    "    front_layers=pretrained_model.transformer_front.nlayers,\n",
    "    rear_layers=pretrained_model.transformer_rear.nlayers,\n",
    "    ntokens=pretrained_model.transformer_front.ntokens,\n",
    "    nhead=pretrained_model.transformer_front.nhead,\n",
    "    pos_emb=True if pretrained_model.transformer_front.pos_emb else False,\n",
    "    n_parser_layers=pretrained_model.n_parse_layers,\n",
    "    pad=pretrained_model.transformer_front.pad\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = structformer_in_parser.StructFormer_In_ParserModel(config).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_state_dict = pretrained_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_state_dict = {f\"model.{k}\": v for k, v in loaded_state_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(loaded_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "structformer_in_parser.StructFormer_In_ParserConfig.register_for_auto_class()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "structformer_in_parser.StructFormer_In_ParserModel.register_for_auto_class(\"AutoModelForMaskedLM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "structformer_in_parser.StructFormer_In_ParserModelForSequenceClassification.register_for_auto_class(\"AutoModelForSequenceClassification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.save_pretrained('../saved_hf_models/sf_ip_babylm_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../saved_hf_models/sf_ip_babylm_1/tokenizer_config.json',\n",
       " '../saved_hf_models/sf_ip_babylm_1/special_tokens_map.json',\n",
       " '../saved_hf_models/sf_ip_babylm_1/vocab.json',\n",
       " '../saved_hf_models/sf_ip_babylm_1/merges.txt',\n",
       " '../saved_hf_models/sf_ip_babylm_1/added_tokens.json',\n",
       " '../saved_hf_models/sf_ip_babylm_1/tokenizer.json')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained('../saved_hf_models/sf_ip_babylm_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('../saved_hf_models/sf_ip_babylm_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "structformer_in_parser.StructFormer_In_ParserConfig.register_for_auto_class()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "structformer_in_parser.StructFormer_In_ParserModel.register_for_auto_class(\"AutoModelForMaskedLM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "structformer_in_parser.StructFormer_In_ParserModelForSequenceClassification.register_for_auto_class(\"AutoModelForSequenceClassification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/miniconda3/envs/structformer/lib/python3.6/site-packages/huggingface_hub/hf_api.py:1004: FutureWarning: `create_repo` now takes `token` as an optional positional argument. Be sure to adapt your code!\n",
      "  FutureWarning,\n",
      "Cloning https://huggingface.co/omarmomen/sf_ip_babylm_1 into local empty directory.\n",
      "To https://huggingface.co/omarmomen/sf_ip_babylm_1\n",
      "   b0d898e..8c4e1ea  main -> main\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/omarmomen/sf_ip_babylm_1/commit/8c4e1eaffe20356e67b6814ef30602843c78330d'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.push_to_hub(\"sf_ip_babylm_1\", use_temp_dir=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/miniconda3/envs/structformer/lib/python3.6/site-packages/huggingface_hub/hf_api.py:1004: FutureWarning: `create_repo` now takes `token` as an optional positional argument. Be sure to adapt your code!\n",
      "  FutureWarning,\n",
      "Cloning https://huggingface.co/omarmomen/sf_ip_babylm_1 into local empty directory.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b8b6988399847528cdb3748491341d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 1.00/159M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/omarmomen/sf_ip_babylm_1\n",
      "   8c4e1ea..a1cab64  main -> main\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/omarmomen/sf_ip_babylm_1/commit/a1cab646eec7d5201750aec75806ebdea575cf2b'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(\"sf_ip_babylm_1\", use_temp_dir=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import structformer\n",
    "import data_ptb_subword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = torch.load('../trained_models/babylm_1111_tf.pt')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained('omarmomen/babylm_bpe_tokenizer_16k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = structformer.TransformerConfig(\n",
    "    hidden_size=pretrained_model.hidden_size,\n",
    "    nlayers=pretrained_model.nlayers,\n",
    "    ntokens=pretrained_model.ntokens,\n",
    "    nhead=pretrained_model.nhead,\n",
    "    pos_emb=True if pretrained_model.pos_emb else False,\n",
    "    pad=pretrained_model.pad\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = structformer.TransformerModel(config).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_state_dict = pretrained_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_state_dict = {f\"model.{k}\": v for k, v in loaded_state_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.load_state_dict(loaded_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structformer.TransformerConfig.register_for_auto_class()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structformer.TransformerModel.register_for_auto_class(\"AutoModelForMaskedLM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structformer.TransformerModelForSequenceClassification.register_for_auto_class(\"AutoModelForSequenceClassification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.save_pretrained('../saved_hf_models/tf_babylm_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../saved_hf_models/tf_babylm_1/tokenizer_config.json',\n",
       " '../saved_hf_models/tf_babylm_1/special_tokens_map.json',\n",
       " '../saved_hf_models/tf_babylm_1/vocab.json',\n",
       " '../saved_hf_models/tf_babylm_1/merges.txt',\n",
       " '../saved_hf_models/tf_babylm_1/added_tokens.json',\n",
       " '../saved_hf_models/tf_babylm_1/tokenizer.json')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer.save_pretrained('../saved_hf_models/tf_babylm_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('../saved_hf_models/tf_babylm_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structformer.TransformerConfig.register_for_auto_class()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structformer.TransformerModel.register_for_auto_class(\"AutoModelForMaskedLM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structformer.TransformerModelForSequenceClassification.register_for_auto_class(\"AutoModelForSequenceClassification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/miniconda3/envs/structformer/lib/python3.6/site-packages/huggingface_hub/hf_api.py:1004: FutureWarning: `create_repo` now takes `token` as an optional positional argument. Be sure to adapt your code!\n",
      "  FutureWarning,\n",
      "Cloning https://huggingface.co/omarmomen/tf_babylm_1 into local empty directory.\n",
      "To https://huggingface.co/omarmomen/tf_babylm_1\n",
      "   e7f5a03..bfdf249  main -> main\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/omarmomen/tf_babylm_1/commit/bfdf2495895a1fe407268f60566fa515bb364526'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer.push_to_hub(\"tf_babylm_1\", use_temp_dir=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/miniconda3/envs/structformer/lib/python3.6/site-packages/huggingface_hub/hf_api.py:1004: FutureWarning: `create_repo` now takes `token` as an optional positional argument. Be sure to adapt your code!\n",
      "  FutureWarning,\n",
      "Cloning https://huggingface.co/omarmomen/tf_babylm_1 into local empty directory.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "414ad1ebff5d4b69878919941e12fa77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 1.00/129M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/omarmomen/tf_babylm_1\n",
      "   bfdf249..c799e10  main -> main\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/omarmomen/tf_babylm_1/commit/c799e1058ce933bd3661d89d5f274640b3bd5bf6'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.push_to_hub(\"tf_babylm_1\", use_temp_dir=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "structformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
